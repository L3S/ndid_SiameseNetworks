# -*- coding: utf-8 -*-
"""Computing embeddings for siamese networks example.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1d10wqO7gADCU_jnpP7-VOnDpYyEsMjYx
"""
import sys
sys.path.append("..")

from src.data.embeddings import *
from utils.common import *
from utils.distance import *
from src.model.alexnet import AlexNetModel
from tensorflow.keras import layers, Model

from tqdm import tqdm
from pathlib import Path

"""## Load dataset and pretrained model backbone

### Model

Load the pretrained model from TF Hub. When building, we pass the input size that the model expects.
"""

# create model
alexnet = AlexNetModel()
alexnet.compile()
# alexnet.summary()

train_ds, test_ds, validation_ds = AlexNetModel.x_dataset()

# load weights
# alexnet.fit(train_ds, validation_data=test_ds)
# alexnet.save_weights(get_modeldir('cifar10_alexnet1304.h5'))
# alexnet.evaluate(validation_ds)
alexnet.load_weights(get_modeldir('cifar10_alexnet1304.h5'))

# image features
embedding_model = Model(inputs=alexnet.input, outputs=alexnet.output)
# for layer in embedding_model.layers:
#     layer.trainable = False
# embedding_model.summary()

"""### Dataset

CIFAR 10 has shape 32x32 but the model expects 384x384, so we upsize the image (NOTE: this will likely lead to very bad performance, but it's because of CIFAR rather than the method itself. Consider using a dataset with higher image resolution; for first tests, stick to something available as tensorflow_dataset to speed up things a lot)
"""

(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar10.load_data()
images = np.concatenate([train_images, test_images])
labels = np.concatenate([train_labels, test_labels])
embedding_vds = tf.data.Dataset.from_tensor_slices((images, labels))
embedding_vds = embedding_vds.map(process_images_couple, num_parallel_calls=tf.data.AUTOTUNE, deterministic=False)

# Add batch and prefetch to dataset to speed up processing
BATCH_SIZE = 256
embedding_vds = embedding_vds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)

# Dataset has keys "id" (that we ignore), "image" and "label".
# "image" has shape [BATCH_SIZE,32,32,3] and is an RGB uint8 image
# "label" has shape [BATCH_SIZE,1] and is an integer label (value between 0 and 9)

"""## Precompute embeddings for all dataset images

Since the network is frozen, to speed up training it's better to precalculate the image features for each image in the dataset and only use those values to train the siamese model.

For each image, we keep its label and the image features extracted by the model.
At the end, we save the computed embeddings as a Pandas dataframe, so they can be loaded back quickly without having to recompute them every time.

**NOTE**: Run this on a GPU-enabled runtime or it will take forever
"""

embeddings = embedding_model.predict(embedding_vds)
embedding_labels = np.concatenate([y for x, y in embedding_vds], axis=0)
embedding_labels = np.concatenate(embedding_labels).ravel()  # unwrap from single item array

pred_true = 0
pred_false = 0
i = 0
for e in embeddings:
    class_p = np.argmax(e)
    class_l = embedding_labels[i]
    i += 1
    if class_p == class_l:
        pred_true += 1
    else:
        pred_false += 1

print(pred_true, pred_false)
# 57k true, 3k false